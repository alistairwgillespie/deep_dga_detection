{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DGA Detection, Feature Engineering\n",
    "\n",
    "This notebook is broken down into the following tasks:\n",
    "\n",
    "* Clean and pre-process the data.\n",
    "* Standardization and normalization of numerical variables\n",
    "* Define features for harmonic sequencing\n",
    "* Create train/test `.csv` files that hold the relevant features and class labels for train/test data points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def days_since_creation(domain):\n",
    "    \"\"\"\n",
    "    Gets days since creation\n",
    "    \"\"\"\n",
    "#     try:\n",
    "    # Get creation date of Domain \n",
    "    creation_date = domain.creation_date\n",
    "\n",
    "    # Handling exceptions\n",
    "    if type(creation_date) is list:\n",
    "        creation_date = creation_date[0]\n",
    "    elif str(creation_date).find('Aug'):\n",
    "        creation_date = \"1996-07-01\"\n",
    "    delta = (datetime.today().date() - datetime.strptime(creation_date, '%Y-%m-%d').date()).days\n",
    "    return delta\n",
    "#     except:\n",
    "#         return -1\n",
    "    \n",
    "def days_since_updated(domain):\n",
    "    \"\"\"\n",
    "    Gets days since creation\n",
    "    \"\"\"\n",
    "#     try:\n",
    "    # Get creation date of Domain \n",
    "    updated_date = domain.updated_date\n",
    "\n",
    "    # Handling exceptions\n",
    "    if type(updated_date) is list:\n",
    "        updated_date = updated_date[0]\n",
    "    elif str(updated_date).find('Aug'):\n",
    "        updated_date = \"1996-07-01\"\n",
    "    delta = (datetime.today().date() - datetime.strptime(updated_date, '%Y-%m-%d').date()).days\n",
    "    return delta\n",
    "#     except:\n",
    "#         return -1\n",
    "    \n",
    "def days_till_expired(domain):\n",
    "    \"\"\"\n",
    "    Gets days since creation\n",
    "    \"\"\"\n",
    "#     try:\n",
    "    # Get creation date of Domain \n",
    "    expiration_date = domain.expiration_date\n",
    "    # Handling exceptions\n",
    "    if type(expiration_date) is list:\n",
    "        expiration_date = expiration_date[0]\n",
    "    elif str(expiration_date).find('Aug'):\n",
    "        expiration_date = \"1996-07-01\"\n",
    "    delta = (datetime.today().date() - datetime.strptime(expiration_date, '%Y-%m-%d').date()).days\n",
    "    return abs(delta)\n",
    "#     except:\n",
    "#         return -1\n",
    "    \n",
    "def whois_features(domain_name):\n",
    "#     try:\n",
    "    whois_info = whois.whois(domain_name)\n",
    "    print(whois_info)\n",
    "    return [days_since_creation(whois_info), days_since_updated(whois_info), days_till_expired(whois_info)]\n",
    "#     except:\n",
    "#         return [-1, -1, -1]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whois_features(\"popcornvod.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whois_features(\"google.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#has_registrarname\n",
    "#has_contactemail\n",
    "#days_since_created\n",
    "#days_since_updated\n",
    "#days_until_expiration\n",
    "#has_registrant_info\n",
    "#has_admincontact_info\n",
    "#has_billingcontact_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whois.whois(\"google.com\").creation_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whois.whois(\"google.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# should be the name of directory you created to save your features data\n",
    "data_dir = 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "establishmenthesitatedetailed.com\n",
      "familyropeinfluencecakelunch.com\n",
      "peopledoubtreportfaultbreak.com\n",
      "partytermprogramkickhost.com\n",
      "brainconditionwashnegotiate.com\n",
      "eyereasondealfearsendsize.com\n",
      "requirementallowremember.com\n",
      "tackleinstallreservecontribute.com\n",
      "kindintendmatterwordclub.com\n",
      "racetrustmilkdiscoverbirth.com\n"
     ]
    }
   ],
   "source": [
    "# take a look at some matsnu example domains\n",
    "from dga import matsnu\n",
    "\n",
    "for i in range(10):\n",
    "    print(matsnu.generate_domain())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matsnu Shape: (20000, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stuffregistershelterpitch.com</td>\n",
       "      <td>dga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cookiedisappointedreserve.com</td>\n",
       "      <td>dga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>insectpraypayestimatespite.com</td>\n",
       "      <td>dga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mediahurrydealgolfbringemploy.com</td>\n",
       "      <td>dga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yardlandapologizedetermine.com</td>\n",
       "      <td>dga</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              domain label\n",
       "0      stuffregistershelterpitch.com   dga\n",
       "1      cookiedisappointedreserve.com   dga\n",
       "2     insectpraypayestimatespite.com   dga\n",
       "3  mediahurrydealgolfbringemploy.com   dga\n",
       "4     yardlandapologizedetermine.com   dga"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matsnu domains\n",
    "matsnu_list = []\n",
    "\n",
    "for i in range(20000):\n",
    "    matsnu_list.append(matsnu.generate_domain())\n",
    "    \n",
    "matsnu_df = pd.DataFrame(matsnu_list, columns=['domain'])\n",
    "\n",
    "print(\"Matsnu Shape:\", matsnu_df.shape)\n",
    "\n",
    "matsnu_df['label'] = 'dga'\n",
    "\n",
    "matsnu_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save in data file\n",
    "matsnu_df.to_csv(data_dir + \"/matsnu.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>google.com</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>youtube.com</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>facebook.com</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>baidu.com</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>wikipedia.org</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          domain   label\n",
       "1     google.com  benign\n",
       "2    youtube.com  benign\n",
       "3   facebook.com  benign\n",
       "4      baidu.com  benign\n",
       "5  wikipedia.org  benign"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alex top 1 million domains\n",
    "alexa_df = pd.read_csv(data_dir + \"/alexa_top_1m.csv\", names=['domain'])\n",
    "\n",
    "alexa_df['label'] = 'benign'\n",
    "\n",
    "alexa_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([alexa_df.iloc[:20000], matsnu_df.iloc[:20000]], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>google.com</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>youtube.com</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>facebook.com</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>baidu.com</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wikipedia.org</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          domain   label\n",
       "0     google.com  benign\n",
       "1    youtube.com  benign\n",
       "2   facebook.com  benign\n",
       "3      baidu.com  benign\n",
       "4  wikipedia.org  benign"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test[['days_since_creation', 'days_since_updated', 'days_till_expired']] = test.apply(\n",
    "#     lambda x: whois_features(test['domain']), \n",
    "#     axis=1\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test['domain'].apply(lambda x: whois_features(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = train_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall whois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import whois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(whois.query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in c:\\users\\gilleal\\appdata\\local\\continuum\\anaconda3\\envs\\local_dga\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\gilleal\\appdata\\local\\continuum\\anaconda3\\envs\\local_dga\\lib\\site-packages (from sklearn) (0.22.2.post1)\n",
      "Requirement already satisfied: scipy>=0.17.0 in c:\\users\\gilleal\\appdata\\local\\continuum\\anaconda3\\envs\\local_dga\\lib\\site-packages (from scikit-learn->sklearn) (1.3.2)\n",
      "Requirement already satisfied: numpy>=1.11.0 in c:\\users\\gilleal\\appdata\\local\\continuum\\anaconda3\\envs\\local_dga\\lib\\site-packages (from scikit-learn->sklearn) (1.18.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\gilleal\\appdata\\local\\continuum\\anaconda3\\envs\\local_dga\\lib\\site-packages (from scikit-learn->sklearn) (0.14.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import labelencoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# instantiate labelencoder object\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "5    0\n",
       "6    0\n",
       "7    0\n",
       "8    0\n",
       "9    0\n",
       "Name: label, dtype: int32"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply le on categorical feature columns\n",
    "train_df['label'] = le.fit_transform(train_df['label'])\n",
    "\n",
    "train_df['label'].head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local_dga",
   "language": "python",
   "name": "local_dga"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
