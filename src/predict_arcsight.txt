CREATE or REPLACE FUNCTION dga_parser (domain_strings text[])

    RETURNS SETOF domain

AS $$
import os
import sys
import json
import time
import numpy as np
import pandas as pd
from datetime import datetime
from importlib import import_module, reload
import torch
import math
from collections import Counter
from torch.nn.utils.rnn import pad_sequence
from torch.utils.data import DataLoader
from dga.models.dga_classifier import DGAClassifier
from dga.datasets.domain_dataset import DomainDataset


model_dir = 'models/'
model_info = {}
model_info_path = os.path.join(model_dir, '1595825381_dga_model_info.pth')

with open(model_info_path, 'rb') as f:
    model_info = torch.load(f)

print("model_info: {}".format(model_info))

# Determine the device and construct the model.
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = DGAClassifier(input_features=model_info['input_features'],
                    hidden_dim=model_info['hidden_dim'],
                    n_layers=model_info['n_layers'],
                    output_dim=model_info['output_dim'],
                    embedding_dim=model_info['embedding_dim'],
                    batch_size=model_info['batch_size'])

# Load the stored model parameters.
model_path = os.path.join(model_dir, '1595825381_dga_model.pth')
with open(model_path, 'rb') as f:
    model.load_state_dict(torch.load(f))

# set to eval mode, could use no_grad
model.to(device).eval()


def get_clean_param(p):
    return p.lstrip("\"").rstrip("\"")


def get_prediction(df):
    predict_dl = _get_predict_loader(int(model_info['batch_size']), df)
    classes = {0: 'Benign', 1: 'DGA'}
    model.eval()
    predictions = []

    with torch.no_grad():
        for batch_num, (x_padded,  x_lens) in enumerate(predict_dl):
            output = model(x_padded, x_lens)
            y_hat = torch.round(output.data)
            predictions += [classes[int(key)] for key in y_hat.flatten().numpy()]
    return predictions


def _get_predict_loader(batch_size, df):
    print("Getting test and train data loaders.")
    dataset = DomainDataset(df, train=False)
    predict_dl = DataLoader(dataset, batch_size=batch_size, shuffle=False, collate_fn=pad_collate_pred)
    return predict_dl


def pad_collate(batch):
    (xx, yy) = zip(*batch)
        x_lens = [len(x) for x in xx]
        y_lens = [len(y) for y in yy]
    xx_pad = pad_sequence(xx, batch_first=True, padding_value=0)
    return xx_pad, yy, x_lens, y_lens


def pad_collate_pred(batch):
    x_lens = [len(x) for x in batch]
    xx_pad = pad_sequence(batch, batch_first=True, padding_value=0)
    return xx_pad, x_lens


def entropy(s):
    p, lns = Counter(s), float(len(s))
    return -sum(count/lns * math.log(count/lns, 2) for count in p.values())

domain_df = pd.DataFrame(data=domain_strings)
dga_pred = get_prediction(domain_df)
return [list(elem) for elem in list(zip(domains, dga_pred))])

$$ LANGUAGE plpythonu;

CREATE TYPE domain AS (
    domain_string text,
    dga_pred text,
);

