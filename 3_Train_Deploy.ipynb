{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DGA Detection, Modeling and Learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.utils.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls -la data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# should be the name of directory you created to save your features data\n",
    "data_dir = 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "commentprintreasonneckdare.com\n",
      "kingrepresentfirmcommunicate.com\n",
      "groundtranslatechallenge.com\n",
      "midnightclaimsourcereduce.com\n",
      "clouddisappointedentrance.com\n",
      "wheelpositionboxkneedeal.com\n",
      "dotexercisebidboneimprove.com\n",
      "clickshockdumpamazingcomment.com\n",
      "toprevealpressreplymarried.com\n",
      "platformruinsmokesmartbone.com\n"
     ]
    }
   ],
   "source": [
    "# take a look at some matsnu example domains\n",
    "from dga import matsnu\n",
    "\n",
    "for i in range(10):\n",
    "    print(matsnu.generate_domain())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matsnu Shape: (10000, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chocolateneckcarpetcarereceive.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>financecarrychartreducediscover.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>freedomnailrewardholdhang.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>boardpleasureoccasionraise.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>writerdoesclubrubprintpriest.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                domain\n",
       "0   chocolateneckcarpetcarereceive.com\n",
       "1  financecarrychartreducediscover.com\n",
       "2        freedomnailrewardholdhang.com\n",
       "3       boardpleasureoccasionraise.com\n",
       "4     writerdoesclubrubprintpriest.com"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matsnu_list = []\n",
    "\n",
    "for i in range(10000):\n",
    "    matsnu_list.append(matsnu.generate_domain())\n",
    "    \n",
    "matsnu_df = pd.DataFrame(matsnu_list, columns=['domain'])\n",
    "\n",
    "print(\"Matsnu Shape:\", matsnu_df.shape)\n",
    "\n",
    "matsnu_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save in data file\n",
    "matsnu_df.to_csv(data_dir + \"/matsnu.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alex top 1 million\n",
    "read_csv(data_dir + \"/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Modeling\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import subprocess as sb \n",
      "import sys \n",
      "\n",
      "sb.call([sys.executable, \"-m\", \"pip\", \"install\", 'pandas']) \n",
      "\n",
      "import argparse\n",
      "import json\n",
      "import os\n",
      "import pandas as pd\n",
      "import torch\n",
      "import torch.optim as optim\n",
      "import torch.utils.data\n",
      "\n",
      "# imports the model in model.py by name\n",
      "from model import BinaryClassifier\n",
      "\n",
      "\n",
      "def model_fn(model_dir):\n",
      "    \"\"\"Load the PyTorch model from the `model_dir` directory.\"\"\"\n",
      "    print(\"Loading model.\")\n",
      "\n",
      "    # First, load the parameters used to create the model.\n",
      "    model_info = {}\n",
      "    model_info_path = os.path.join(model_dir, 'model_info.pth')\n",
      "    with open(model_info_path, 'rb') as f:\n",
      "        model_info = torch.load(f)\n",
      "\n",
      "    print(\"model_info: {}\".format(model_info))\n",
      "\n",
      "    # Determine the device and construct the model.\n",
      "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
      "    model = BinaryClassifier(model_info['input_features'], model_info['hidden_dim'], model_info['output_dim'])\n",
      "\n",
      "    # Load the stored model parameters.\n",
      "    model_path = os.path.join(model_dir, 'model.pth')\n",
      "    with open(model_path, 'rb') as f:\n",
      "        model.load_state_dict(torch.load(f))\n",
      "\n",
      "    # set to eval mode, could use no_grad\n",
      "    model.to(device).eval()\n",
      "\n",
      "    print(\"Done loading model.\")\n",
      "    return model\n",
      "\n",
      "# Gets training data in batches from the train.csv file\n",
      "def _get_train_data_loader(batch_size, training_dir):\n",
      "    print(\"Get train data loader.\")\n",
      "\n",
      "    train_data = pd.read_csv(os.path.join(training_dir, \"train.csv\"), header=None, names=None)\n",
      "\n",
      "    train_y = torch.from_numpy(train_data[[0]].values).float().squeeze()\n",
      "    train_x = torch.from_numpy(train_data.drop([0], axis=1).values).float()\n",
      "\n",
      "    train_ds = torch.utils.data.TensorDataset(train_x, train_y)\n",
      "\n",
      "    return torch.utils.data.DataLoader(train_ds, batch_size=batch_size)\n",
      "\n",
      "\n",
      "# Provided training function\n",
      "def train(model, train_loader, epochs, criterion, optimizer, device):\n",
      "    \"\"\"\n",
      "    This is the training method that is called by the PyTorch training script. The parameters\n",
      "    passed are as follows:\n",
      "    model        - The PyTorch model that we wish to train.\n",
      "    train_loader - The PyTorch DataLoader that should be used during training.\n",
      "    epochs       - The total number of epochs to train for.\n",
      "    criterion    - The loss function used for training. \n",
      "    optimizer    - The optimizer to use during training.\n",
      "    device       - Where the model and data should be loaded (gpu or cpu).\n",
      "    \"\"\"\n",
      "    \n",
      "    # training loop is provided\n",
      "    for epoch in range(1, epochs + 1):\n",
      "        model.train() # Make sure that the model is in training mode.\n",
      "\n",
      "        total_loss = 0\n",
      "\n",
      "        for batch in train_loader:\n",
      "            # get data\n",
      "            batch_x, batch_y = batch\n",
      "\n",
      "            batch_x = batch_x.to(device)\n",
      "            batch_y = batch_y.to(device)\n",
      "\n",
      "            optimizer.zero_grad()\n",
      "\n",
      "            # get predictions from model\n",
      "            y_pred = model(batch_x)\n",
      "            \n",
      "            # perform backprop\n",
      "            loss = criterion(y_pred, batch_y)\n",
      "            loss.backward()\n",
      "            optimizer.step()\n",
      "            \n",
      "            total_loss += loss.data.item()\n",
      "\n",
      "        print(\"Epoch: {}, Loss: {}\".format(epoch, total_loss / len(train_loader)))\n",
      "\n",
      "\n",
      "## TODO: Complete the main code\n",
      "if __name__ == '__main__':\n",
      "    \n",
      "    # All of the model parameters and training parameters are sent as arguments\n",
      "    # when this script is executed, during a training job\n",
      "    \n",
      "    # Here we set up an argument parser to easily access the parameters\n",
      "    parser = argparse.ArgumentParser()\n",
      "\n",
      "    # SageMaker parameters, like the directories for training data and saving models; set automatically\n",
      "    # Do not need to change\n",
      "    parser.add_argument('--output-data-dir', type=str, default=os.environ['SM_OUTPUT_DATA_DIR'])\n",
      "    parser.add_argument('--model-dir', type=str, default=os.environ['SM_MODEL_DIR'])\n",
      "    parser.add_argument('--data-dir', type=str, default=os.environ['SM_CHANNEL_TRAIN'])\n",
      "    \n",
      "    # Training Parameters, given\n",
      "    parser.add_argument('--batch-size', type=int, default=10, metavar='N',\n",
      "                        help='input batch size for training (default: 10)')\n",
      "    parser.add_argument('--epochs', type=int, default=10, metavar='N',\n",
      "                        help='number of epochs to train (default: 10)')\n",
      "    parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
      "                        help='random seed (default: 1)')\n",
      "    \n",
      "    ## TODO: Add args for the three model parameters: input_features, hidden_dim, output_dim\n",
      "    # Model Parameters\n",
      "    \n",
      "    parser.add_argument('--input_features', type=int, default=3, metavar='N',\n",
      "                        help='size of the feature space (default: 2)')\n",
      "    parser.add_argument('--hidden_dim', type=int, default=2, metavar='N',\n",
      "                        help='size of the hidden dimension (default: 100)')\n",
      "    parser.add_argument('--output_dim', type=int, default=1, metavar='N',\n",
      "                        help='size of the output dimension (default: 4)')\n",
      "    parser.add_argument('--lr', type=float, default=1e-3,\n",
      "                        help='learning rate (default: 1e-3)')\n",
      "    \n",
      "    # args holds all passed-in arguments\n",
      "    args = parser.parse_args()\n",
      "\n",
      "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
      "    print(\"Using device {}.\".format(device))\n",
      "\n",
      "    torch.manual_seed(args.seed)\n",
      "\n",
      "    # Load the training data.\n",
      "    train_loader = _get_train_data_loader(args.batch_size, args.data_dir)\n",
      "\n",
      "\n",
      "    ## --- Your code here --- ##\n",
      "    \n",
      "    ## TODO:  Build the model by passing in the input params\n",
      "    # To get params from the parser, call args.argument_name, ex. args.epochs or ards.hidden_dim\n",
      "    # Don't forget to move your model .to(device) to move to GPU , if appropriate\n",
      "    model = BinaryClassifier(args.input_features, args.hidden_dim, args.output_dim).to(device)\n",
      "\n",
      "    ## TODO: Define an optimizer and loss function for training\n",
      "    optimizer = optim.Adam(model.parameters(), args.lr)\n",
      "    criterion = torch.nn.BCELoss()\n",
      "\n",
      "    # Trains the model (given line of code, which calls the above training function)\n",
      "    train(model, train_loader, args.epochs, criterion, optimizer, device)\n",
      "\n",
      "    ## TODO: complete in the model_info by adding three argument names, the first is given\n",
      "    # Keep the keys of this dictionary as they are \n",
      "    model_info_path = os.path.join(args.model_dir, 'model_info.pth')\n",
      "    with open(model_info_path, 'wb') as f:\n",
      "        model_info = {\n",
      "            'input_features': args.input_features,\n",
      "            'hidden_dim': args.hidden_dim,\n",
      "            'output_dim': args.output_dim\n",
      "        }\n",
      "        torch.save(model_info, f)\n",
      "        \n",
      "    ## --- End of your code  --- ##\n",
      "    \n",
      "\n",
      "\t# Save the model parameters\n",
      "    model_path = os.path.join(args.model_dir, 'model.pth')\n",
      "    with open(model_path, 'wb') as f:\n",
      "        torch.save(model.cpu().state_dict(), f)\n"
     ]
    }
   ],
   "source": [
    "# Directory of train.py\n",
    "!pygmentize model/train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch imports\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "class LSTMClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    This is the simple RNN model we will be using to perform Sentiment Analysis.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size):\n",
    "        \"\"\"\n",
    "        Initialize the model by settingg up the various layers.\n",
    "        \"\"\"\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "        self.dense = nn.Linear(in_features=hidden_dim, out_features=1)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "        self.word_dict = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Perform a forward pass of our model on some input.\n",
    "        \"\"\"\n",
    "        x = x.t()\n",
    "        lengths = x[0,:]\n",
    "        reviews = x[1:,:]\n",
    "        embeds = self.embedding(reviews)\n",
    "        lstm_out, _ = self.lstm(embeds)\n",
    "        out = self.dense(lstm_out)\n",
    "        out = out[lengths - 1, range(len(lengths))]\n",
    "        return self.sig(out.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Create an Estimator\n",
    "\n",
    "\n",
    "\n",
    "## Define PyTorch estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-d567d339c3c7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mtrain_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"train.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mtrain_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_dir' is not defined"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv(os.path.join(data_dir, \"train.csv\"), header=None, names=None)\n",
    "\n",
    "train_y = torch.from_numpy(train_data[[0]].values).float().squeeze()\n",
    "train_x = torch.from_numpy(train_data.drop([0], axis=1).values).float()\n",
    "\n",
    "train_ds = torch.utils.data.TensorDataset(train_x, train_y)\n",
    "\n",
    "train_sample_dl = torch.utils.data.DataLoader(train_ds, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function for LSTM\n",
    "def train_lstm(model, train_loader, epochs, criterion, optimizer, device):\n",
    "    \"\"\"\n",
    "    This is the training method that is called by the PyTorch training script of the LSTM model. The parameters\n",
    "    passed are as follows:\n",
    "    model        - The PyTorch model that we wish to train.\n",
    "    train_loader - The PyTorch DataLoader that should be used during training.\n",
    "    epochs       - The total number of epochs to train for.\n",
    "    criterion    - The loss function used for training. \n",
    "    optimizer    - The optimizer to use during training.\n",
    "    device       - Where the model and data should be loaded (gpu or cpu).\n",
    "    \"\"\"\n",
    "    \n",
    "    # training loop is provided\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        \n",
    "        model.train() # Make sure that the model is in training mode.\n",
    "\n",
    "        total_loss = 0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            \n",
    "            # get data\n",
    "            batch_x, batch_y = batch\n",
    "            \n",
    "            # \n",
    "            batch_x = torch.from_numpy(batch_x).float().squeeze()\n",
    "            batch_y = torch.from_numpy(batch_y).float()\n",
    "\n",
    "            batch_x = batch_x.to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            model.hidden_cell = (torch.zeros(1, 1, model.hidden_layer_dim),\n",
    "                torch.zeros(1, 1, model.hidden_layer_dim))\n",
    "\n",
    "            # get predictions from model\n",
    "            y_pred = model(batch_x)\n",
    "            \n",
    "            # perform backprop\n",
    "            loss = criterion(y_pred, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.data.item()\n",
    "            \n",
    "        if epoch%25 == 1:\n",
    "            print(\"Epoch: {}, Loss: {}\".format(epoch, total_loss / len(train_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'source_pytorch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-3ec9167473a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msource_pytorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBinaryClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cuda\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"cpu\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBinaryClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'source_pytorch'"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "# from model.LSTM_Estimator import LSTMEstimator\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = LSTMEstimator(8, 30, 1, 8)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "loss_fn = torch.nn.L1Loss()\n",
    "\n",
    "train_lstm(model, processed_data, 100, loss_fn, optimizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local_wmw",
   "language": "python",
   "name": "local_wmw"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
